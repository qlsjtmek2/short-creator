import ffmpeg from 'fluent-ffmpeg';
import * as fs from 'fs';
import * as path from 'path';
import { createCanvas, registerFont } from 'canvas';
import { IStoryVideoRenderer, EditorSegment } from '../../types/interfaces';
import { StoryScriptWithAssets } from '../../types/common';
import { RENDER_CONFIG } from '../config/render-config';
import {
  RenderManifest,
  ImageElement,
  TitleElement,
  SubtitleChunk,
  AudioElement,
} from '../../types/rendering';

/**
 * íƒ€ì´í‹€ í…ìŠ¤íŠ¸ ì„¸ê·¸ë¨¼íŠ¸ (ì¼ë°˜ í…ìŠ¤íŠ¸ ë˜ëŠ” ê°•ì¡° í…ìŠ¤íŠ¸)
 */
interface TitleSegment {
  text: string;
  isHighlight: boolean;
}

/**
 * FFmpegë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¤í† ë¦¬í…”ë§ ì‡¼ì¸ ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤.
 * - ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ + Ken Burns Zoom-in íš¨ê³¼
 * - ìƒ/í•˜ë‹¨ ë ˆí„°ë°•ìŠ¤
 * - ìƒë‹¨ íƒ€ì´í‹€ í…ìŠ¤íŠ¸ (ìë™ ì¤„ë°”ê¿ˆ + í‚¤ì›Œë“œ ê°•ì¡°)
 * - ASS ìë§‰ ì˜¤ë²„ë ˆì´
 * - ë¬¸ì¥ë³„ ì˜¤ë””ì˜¤ ë³‘í•© + BGM ë¯¹ì‹±
 */
export class FFmpegStoryRenderer implements IStoryVideoRenderer {
  // RENDER_CONFIG ì‚¬ìš©
  private config = { ...RENDER_CONFIG };

  /**
   * ìŠ¤í† ë¦¬ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì˜ìƒìœ¼ë¡œ ë Œë”ë§í•©ë‹ˆë‹¤.
   */
  async render(
    script: StoryScriptWithAssets,
    subtitlePath: string,
    outputPath: string,
    titleFont?: string,
    bgmFile?: string,
    editorSegments?: EditorSegment[],
  ): Promise<string> {
    // íŒŒì¼ëª…ìœ¼ë¡œë¶€í„° ì ˆëŒ€ ê²½ë¡œ ìƒì„±
    const titleFontFile = titleFont || 'Pretendard-ExtraBold.ttf';
    const bgmFileName = bgmFile || 'bgm2.mp3';

    this.config.title.fontPath = path.resolve(
      process.cwd(),
      'assets/fonts',
      titleFontFile,
    );
    this.config.audio.bgmPath = path.resolve(
      process.cwd(),
      'assets/music',
      bgmFileName,
    );

    const bgmPath = this.config.audio.bgmPath;
    console.log('  ğŸ¬ Starting FFmpeg rendering...');

    // ì¶œë ¥ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
    const outputDir = path.dirname(outputPath);
    if (!fs.existsSync(outputDir)) {
      fs.mkdirSync(outputDir, { recursive: true });
    }

    const mergedAudioPath = path.join(
      path.dirname(outputPath),
      `merged_audio_${Date.now()}.mp3`,
    );

    await this.concatAudioWithDelay(
      script.sentences.map((s, idx) => ({
        path: s.audioPath!,
        delay: editorSegments ? editorSegments[idx]?.delay || 0 : 0,
      })),
      mergedAudioPath,
    );
    console.log('  âœ“ Audio files merged');

    // 2. ì˜ìƒ ë Œë”ë§ (ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ + íš¨ê³¼)
    await this.renderVideo(
      script,
      mergedAudioPath,
      subtitlePath,
      outputPath,
      bgmPath,
      editorSegments,
    );
    console.log('  âœ“ Video rendering complete');

    // ì„ì‹œ íŒŒì¼ ì •ë¦¬
    if (fs.existsSync(mergedAudioPath)) {
      fs.unlinkSync(mergedAudioPath);
    }

    return outputPath;
  }

  /**
   * (Phase 21) RenderManifestë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ìƒì„ ë Œë”ë§í•©ë‹ˆë‹¤. (SSOT)
   */
  async renderFromManifest(
    manifest: RenderManifest,
    outputPath: string,
    titleFont?: string,
  ): Promise<string> {
    const titleFontFile = titleFont || 'Pretendard-ExtraBold.ttf';
    this.config.title.fontPath = path.resolve(
      process.cwd(),
      'assets/fonts',
      titleFontFile,
    );

    console.log('  ğŸ¬ Starting FFmpeg rendering from Manifest...');

    const outputDir = path.dirname(outputPath);
    if (!fs.existsSync(outputDir)) {
      fs.mkdirSync(outputDir, { recursive: true });
    }

    return new Promise((resolve, reject) => {
      const command = ffmpeg();
      const inputs: string[] = [];
      const imageElements = manifest.elements.filter(
        (e) => e.type === 'image',
      ) as ImageElement[];
      const audioElements = manifest.elements.filter(
        (e) => e.type === 'audio',
      ) as AudioElement[];

      // 1. Image Inputs
      imageElements.forEach((el) => {
        const isGif = el.src.toLowerCase().endsWith('.gif');
        const duration = (el.endFrame - el.startFrame) / manifest.metadata.fps;

        if (isGif) {
          command
            .input(el.src)
            .inputOptions(['-stream_loop', '-1', '-t', duration.toString()]);
        } else {
          command.input(el.src);
        }
        inputs.push(`[${inputs.length}:v]`);
      });

      // 2. Audio Inputs
      audioElements.forEach((el) => {
        command.input(el.src);
        inputs.push(`[${inputs.length}:a]`);
      });

      // 3. Filter Complex
      const filterComplex = this.buildFilterComplexFromManifest(
        manifest,
        imageElements.length,
      );

      const ffmpegCommand = command
        .complexFilter(filterComplex)
        .outputOptions([
          '-map',
          '[final_video]',
          '-map',
          '[final_audio]',
          '-c:v',
          this.config.rendering.videoCodec,
          '-preset',
          this.config.rendering.preset,
          '-crf',
          this.config.rendering.crf.toString(),
          '-r',
          manifest.metadata.fps.toString(),
          '-pix_fmt',
          this.config.rendering.pixelFormat,
          '-c:a',
          this.config.rendering.audioCodec,
          '-b:a',
          this.config.rendering.audioBitrate,
        ])
        .output(outputPath);

      ffmpegCommand
        .on('start', (cmd: string) => console.log('  ğŸ“¹ FFmpeg command:', cmd))
        .on('end', () => {
          console.log('  âœ“ Video rendering complete');
          resolve(outputPath);
        })
        .on('error', (err: Error) => {
          console.error('FFmpeg error:', err.message);
          reject(new Error(`Video rendering failed: ${err.message}`));
        })
        .run();
    });
  }

  /**
   * ë¬¸ì¥ë³„ ì˜¤ë””ì˜¤ íŒŒì¼ë“¤ì„ í•˜ë‚˜ë¡œ ë³‘í•©í•©ë‹ˆë‹¤. (ë”œë ˆì´ í¬í•¨)
   */
  private async concatAudioWithDelay(
    audioSegments: { path: string; delay: number }[],
    outputPath: string,
  ): Promise<void> {
    return new Promise((resolve, reject) => {
      const tempDir = path.dirname(outputPath);
      const concatContent = audioSegments
        .map((s) => `file '${path.resolve(s.path)}'`)
        .join('\n');

      const concatListPath = path.join(
        tempDir,
        `concat_list_${Date.now()}.txt`,
      );
      fs.writeFileSync(concatListPath, concatContent);

      const command = ffmpeg();
      command
        .input(concatListPath)
        .inputOptions(['-f', 'concat', '-safe', '0'])
        .outputOptions(['-c', 'copy'])
        .output(outputPath)
        .on('end', () => {
          if (fs.existsSync(concatListPath)) fs.unlinkSync(concatListPath);
          resolve();
        })
        .on('error', (err: Error) => {
          reject(new Error(`Audio concat failed: ${err.message}`));
        })
        .run();
    });
  }

  /**
   * ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ì™€ ì˜¤ë””ì˜¤ë¥¼ ê²°í•©í•˜ì—¬ ìµœì¢… ì˜ìƒì„ ìƒì„±í•©ë‹ˆë‹¤.
   */
  private async renderVideo(
    script: StoryScriptWithAssets,
    audioPath: string,
    subtitlePath: string,
    outputPath: string,
    bgmPath?: string,
    editorSegments?: EditorSegment[],
  ): Promise<void> {
    return new Promise((resolve, reject) => {
      const command = ffmpeg();

      // 1. ì´ë¯¸ì§€ ì…ë ¥
      script.sentences.forEach((s, idx) => {
        // ë”œë ˆì´ê°€ í¬í•¨ëœ ì „ì²´ ì§€ì† ì‹œê°„
        const editorSeg = editorSegments ? editorSegments[idx] : null;
        const delay = editorSeg?.delay || 0;
        const duration = (s.duration || 3) + delay;

        const isGif = s.imagePath?.toLowerCase().endsWith('.gif');

        if (isGif) {
          command
            .input(s.imagePath!)
            .inputOptions(['-stream_loop', '-1', '-t', duration.toString()]);
        } else {
          command.input(s.imagePath!); // Static image
        }
      });

      // 2. ì˜¤ë””ì˜¤ ì…ë ¥ (Merged TTS)
      command.input(audioPath);

      // 3. BGM ì…ë ¥
      if (bgmPath && fs.existsSync(bgmPath)) {
        command.input(bgmPath);
      }

      // 4. SFX ì…ë ¥ (ìˆë‹¤ë©´)
      const sfxInputs: { index: number; type: string; startTime: number }[] =
        [];

      // í˜„ì¬ ì…ë ¥ ê°œìˆ˜ ê³„ì‚° (ì´ë¯¸ì§€ + TTS + BGM?)
      let currentInputIndex = script.sentences.length + 1; // Images + TTS
      if (bgmPath && fs.existsSync(bgmPath)) {
        currentInputIndex++; // BGM
      }

      if (editorSegments) {
        editorSegments.forEach((seg, idx) => {
          if (seg.sfx) {
            const sfxPath = path.resolve(
              process.cwd(),
              `assets/sfx/${seg.sfx}.mp3`,
            );
            // íŒŒì¼ì´ ì¡´ì¬í•œë‹¤ê³  ê°€ì • (í˜¹ì€ ì²´í¬)
            if (fs.existsSync(sfxPath)) {
              command.input(sfxPath);
              sfxInputs.push({
                index: currentInputIndex,
                type: seg.sfx,
                startTime: script.sentences[idx].startTime || 0,
              });
              currentInputIndex++;
            }
          }
        });
      }

      // ë³µì¡í•œ í•„í„° ì²´ì¸ êµ¬ì„±
      const filterComplex = this.buildFilterComplex(
        script,
        subtitlePath,
        !!bgmPath && fs.existsSync(bgmPath),
        editorSegments,
        sfxInputs,
      );

      const ffmpegCommand = command
        .complexFilter(filterComplex)
        .outputOptions([
          '-map',
          '[final_video]',
          '-map',
          '[final_audio]',
          '-c:v',
          this.config.rendering.videoCodec,
          '-preset',
          this.config.rendering.preset,
          '-crf',
          this.config.rendering.crf.toString(),
          '-r',
          this.config.kenBurns.fps.toString(),
          '-pix_fmt',
          this.config.rendering.pixelFormat,
          '-c:a',
          this.config.rendering.audioCodec,
          '-b:a',
          this.config.rendering.audioBitrate,
        ])
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        .output(outputPath) as any;

      ffmpegCommand
        .on('start', (cmd: string) => {
          console.log('  ğŸ“¹ FFmpeg command:', cmd);
        })
        .on('progress', (progress: { percent?: number }) => {
          if (progress.percent) {
            process.stdout.write(
              `\r  Progress: ${progress.percent.toFixed(1)}%`,
            );
          }
        })
        .on('end', () => {
          process.stdout.write('\r');
          resolve();
        })
        .on('error', (err: Error, stdout?: string, stderr?: string) => {
          console.error('FFmpeg error:', err.message);
          console.error('FFmpeg stderr:', stderr);
          reject(new Error(`Video rendering failed: ${err.message}`));
        })
        .run();
    });
  }

  /**
   * FFmpeg ë³µì¡ í•„í„° ì²´ì¸ì„ êµ¬ì„±í•©ë‹ˆë‹¤.
   */
  private buildFilterComplex(
    script: StoryScriptWithAssets,
    subtitlePath: string,
    hasBGM: boolean,
    editorSegments?: EditorSegment[],
    sfxInputs?: { index: number; type: string; startTime: number }[],
  ): string[] {
    const filters: string[] = [];
    const imageCount = script.sentences.length;

    const canvas = this.config.canvas;
    const kb = this.config.kenBurns;

    // Step 1: ê° ì´ë¯¸ì§€ ìŠ¤ì¼€ì¼ë§ + VFX ì ìš©
    script.sentences.forEach((s, i) => {
      // ë”œë ˆì´ í¬í•¨ëœ ì§€ì† ì‹œê°„ ì‚¬ìš©
      const editorSeg = editorSegments ? editorSegments[i] : null;
      const delay = editorSeg?.delay || 0;
      const duration = (s.duration || 3) + delay;

      const totalFrames = Math.floor(duration * kb.fps);
      const isGif = s.imagePath?.toLowerCase().endsWith('.gif');
      const vfx = editorSeg?.vfx || 'zoom-in';

      let vfxFilter = '';
      switch (vfx) {
        case 'zoom-in':
          vfxFilter = `zoompan=z='min(zoom+${kb.zoomIncrement},${kb.endZoom})':d=${totalFrames}:s=${canvas.width}x${canvas.height}:fps=${kb.fps}`;
          break;
        case 'zoom-out':
          // 1.2 -> 1.0
          vfxFilter = `zoompan=z='max(1.2-${kb.zoomIncrement}*on,1.0)':d=${totalFrames}:s=${canvas.width}x${canvas.height}:fps=${kb.fps}`;
          break;
        case 'pan-left':
          // x ì´ë™ (ì¤‘ì‹¬ -> ì™¼ìª½)
          vfxFilter = `zoompan=z=${kb.endZoom}:x='x+1':d=${totalFrames}:s=${canvas.width}x${canvas.height}:fps=${kb.fps}`;
          break;
        case 'pan-right':
          vfxFilter = `zoompan=z=${kb.endZoom}:x='x-1':d=${totalFrames}:s=${canvas.width}x${canvas.height}:fps=${kb.fps}`;
          break;
        case 'shake':
          // x='x+random(1)*10-5':y='y+random(1)*10-5'
          vfxFilter = `zoompan=z=${kb.endZoom}:x='x+random(1)*20-10':y='y+random(1)*20-10':d=${totalFrames}:s=${canvas.width}x${canvas.height}:fps=${kb.fps}`;
          break;
        default: // static
          vfxFilter = `zoompan=z=1.0:d=${totalFrames}:s=${canvas.width}x${canvas.height}:fps=${kb.fps}`;
      }

      if (isGif) {
        filters.push(
          `[${i}:v]scale=${canvas.width}:${canvas.height}:force_original_aspect_ratio=increase,crop=${canvas.width}:${canvas.height},setsar=1[zoomed${i}]`,
        );
      } else {
        filters.push(
          `[${i}:v]scale=${canvas.width}:${canvas.height}:force_original_aspect_ratio=increase,crop=${canvas.width}:${canvas.height},setsar=1[scaled${i}]`,
        );
        filters.push(`[scaled${i}]${vfxFilter}[zoomed${i}]`);
      }
    });

    // Step 2: ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ concat
    const concatInputs = script.sentences
      .map((_, i) => `[zoomed${i}]`)
      .join('');
    filters.push(`${concatInputs}concat=n=${imageCount}:v=1:a=0[concat_video]`);

    // Step 3: ë ˆí„°ë°•ìŠ¤
    const lb = this.config.letterbox;
    filters.push(
      `[concat_video]drawbox=x=0:y=0:w=${canvas.width}:h=${lb.top}:color=${lb.color}:t=fill,drawbox=x=0:y=${canvas.height - lb.bottom}:w=${canvas.width}:h=${lb.bottom}:color=${lb.color}:t=fill[with_letterbox]`,
    );

    // Step 4: íƒ€ì´í‹€
    const titleFilters = this.buildTitleFilters(
      script.title,
      'with_letterbox',
      'titled',
    );
    filters.push(...titleFilters);

    // Step 5: ìë§‰
    const subtitlePathEscaped = subtitlePath
      .replace(/\\/g, '/')
      .replace(/:/g, '\\:');
    filters.push(`[titled]ass='${subtitlePathEscaped}'[final_video]`);

    // Step 6: ì˜¤ë””ì˜¤ ë¯¹ì‹± (TTS + BGM + SFX)
    const audioInputIndex = imageCount; // TTS
    const bgmInputIndex = audioInputIndex + 1; // BGM
    const audio = this.config.audio;

    // TTS ë³¼ë¥¨ ì¡°ì ˆ
    filters.push(`[${audioInputIndex}:a]volume=${audio.ttsVolume}[tts]`);

    const mixInputs = ['[tts]'];

    // BGM
    if (hasBGM) {
      filters.push(
        `[${bgmInputIndex}:a]volume=${audio.bgmVolume},aloop=loop=-1:size=2e+09[bgm_loop]`,
      );
      mixInputs.push('[bgm_loop]');
    }

    // SFX
    if (sfxInputs && sfxInputs.length > 0) {
      sfxInputs.forEach((sfx, idx) => {
        const label = `sfx${idx}`;
        // ë”œë ˆì´ ì ìš© (adelay)
        // adelay=1000|1000 (ms ë‹¨ìœ„, ìŠ¤í…Œë ˆì˜¤ ì±„ë„ ëª¨ë‘ ì ìš©)
        const delayMs = Math.round(sfx.startTime * 1000);
        filters.push(
          `[${sfx.index}:a]adelay=${delayMs}|${delayMs},volume=${audio.sfxVolume}[${label}]`,
        );
        mixInputs.push(`[${label}]`);
      });
    }

    // Final Mix
    filters.push(
      `${mixInputs.join('')}amix=inputs=${mixInputs.length}:duration=first[final_audio]`,
    );

    return filters;
  }

  private buildFilterComplexFromManifest(
    manifest: RenderManifest,
    imageCount: number,
  ): string[] {
    const filters: string[] = [];
    const canvas = manifest.canvas;
    const fps = manifest.metadata.fps;

    // Step 1: Images + Ken Burns
    const imageElements = manifest.elements.filter(
      (e) => e.type === 'image',
    ) as ImageElement[];
    imageElements.forEach((el, i) => {
      const durationFrames = el.endFrame - el.startFrame;
      const isGif = el.src.toLowerCase().endsWith('.gif');
      const { fromScale, toScale } = el.kenBurns;

      // Ken Burns ìˆ˜ì‹
      // zoompanì˜ x, y, zëŠ” í”„ë ˆì„ ë‹¨ìœ„ë¡œ ê³„ì‚°ë¨ (on: output frame number)
      // linear interpolation: start + (end - start) * on / duration
      const zExpr = `${fromScale}+(${toScale}-${fromScale})*on/${durationFrames}`;

      // FFmpeg zoompan ì¢Œí‘œê³„ ë³´ì • (ì¤‘ì‹¬ ê¸°ì¤€ì´ ì•„ë‹˜, ì¢Œìƒë‹¨ ê¸°ì¤€)
      // í•˜ì§€ë§Œ ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœí™”ë¥¼ ìœ„í•´ zoompan ê¸°ë³¸ ë™ì‘ ì‚¬ìš© (ì¤‘ì•™ ì¤‘ì‹¬)
      // ì •í™•í•œ ì¢Œí‘œ ë§¤í•‘ì„ ìœ„í•´ì„œëŠ” x, y ìˆ˜ì‹ ê²€ì¦ í•„ìš”.
      // LayoutEngineì—ì„œ ê³„ì‚°ëœ ê°’ì€ Remotion ê¸°ì¤€(px)ì´ë¯€ë¡œ FFmpeg ì¢Œí‘œê³„ë¡œ ë³€í™˜í•´ì•¼ í•¨.
      // ì¼ë‹¨ ê°„ë‹¨í•œ Zoom In/Outë§Œ êµ¬í˜„.

      const vfxFilter = `zoompan=z='${zExpr}':d=${durationFrames}:s=${canvas.width}x${canvas.height}:fps=${fps}`;
      if (isGif) {
        filters.push(
          `[${i}:v]scale=${canvas.width}:${canvas.height}:force_original_aspect_ratio=increase,crop=${canvas.width}:${canvas.height},setsar=1[zoomed${i}]`,
        );
      } else {
        filters.push(
          `[${i}:v]scale=${canvas.width}:${canvas.height}:force_original_aspect_ratio=increase,crop=${canvas.width}:${canvas.height},setsar=1[scaled${i}]`,
        );
        filters.push(`[scaled${i}]${vfxFilter}[zoomed${i}]`);
      }
    });

    // Step 2: Concat Video
    const concatInputs = imageElements.map((_, i) => `[zoomed${i}]`).join('');
    filters.push(`${concatInputs}concat=n=${imageCount}:v=1:a=0[concat_video]`);

    // Step 3: Letterbox
    const lb = this.config.letterbox;
    filters.push(
      `[concat_video]drawbox=x=0:y=0:w=${canvas.width}:h=${lb.top}:color=${lb.color}:t=fill,drawbox=x=0:y=${canvas.height - lb.bottom}:w=${canvas.width}:h=${lb.bottom}:color=${lb.color}:t=fill[with_letterbox]`,
    );

    // Step 4: Title (using drawtext based on Manifest)
    const titleElement = manifest.elements.find(
      (e) => e.type === 'title_text',
    ) as TitleElement;
    let currentLabel = 'with_letterbox';
    let filterIdx = 0;
    const fontPath = this.getFontPath();

    if (titleElement) {
      titleElement.lines.forEach((line) => {
        line.segments.forEach((seg) => {
          const nextLabel = `title_${filterIdx++}`;
          const color = seg.isHighlight
            ? this.config.title.highlightColor
            : this.config.title.fontColor;
          const escapedText = this.escapeFFmpegText(seg.text);

          filters.push(
            `[${currentLabel}]drawtext=fontfile='${fontPath}':text='${escapedText}':fontcolor=${color}:fontsize=${this.config.title.fontSize}:x=${Math.round(seg.x)}:y=${Math.round(line.y)}:borderw=${this.config.title.borderWidth}:bordercolor=${this.config.title.borderColor}[${nextLabel}]`,
          );
          currentLabel = nextLabel;
        });
      });
    }

    // Step 5: Subtitles (Chunks using drawtext)
    // ì„±ëŠ¥ ì´ìŠˆê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë‚˜ SSOT ê²€ì¦ì„ ìœ„í•´ drawtext ì‚¬ìš©
    // enable='between(n, start, end)' ì‚¬ìš©
    const subtitleChunks = manifest.elements.filter(
      (e) => e.type === 'subtitle_chunk',
    ) as SubtitleChunk[];
    const subFontPath = this.getFontPath(); // ì œëª© í°íŠ¸ì™€ ë™ì¼í•˜ë‹¤ê³  ê°€ì • (ì„¤ì • ë¶„ë¦¬ í•„ìš”)

    subtitleChunks.forEach((chunk, i) => {
      const nextLabel =
        i === subtitleChunks.length - 1 ? 'final_video' : `sub_${i}`;
      const escapedText = this.escapeFFmpegText(chunk.text);
      // ì¤‘ì•™ ì •ë ¬ì„ ìœ„í•´ x=(w-text_w)/2
      // y ì¢Œí‘œëŠ” í•˜ë‹¨ ë ˆí„°ë°•ìŠ¤ ì¤‘ì•™
      const yPos = canvas.height - lb.bottom / 2 - 20;

      // Pop-in ì• ë‹ˆë©”ì´ì…˜ì€ FFmpeg drawtextë¡œ êµ¬í˜„í•˜ê¸° ë§¤ìš° ë³µì¡í•˜ë¯€ë¡œ
      // ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœ í‘œì‹œ(enable)ë§Œ êµ¬í˜„í•˜ê±°ë‚˜, ë³µì¡í•œ ìˆ˜ì‹ì„ ì¨ì•¼ í•¨.
      // ì¼ë‹¨ ë‹¨ìˆœ í‘œì‹œë¡œ êµ¬í˜„.
      filters.push(
        `[${currentLabel}]drawtext=fontfile='${subFontPath}':text='${escapedText}':fontcolor=white:fontsize=${this.config.subtitle.fontSize}:x=(w-text_w)/2:y=${yPos}:enable='between(n,${chunk.startFrame},${chunk.endFrame})':borderw=2:bordercolor=black[${nextLabel}]`,
      );
      currentLabel = nextLabel;
    });

    if (subtitleChunks.length === 0) {
      filters.push(`[${currentLabel}]null[final_video]`);
    }

    // Step 6: Audio Mix
    const audioElements = manifest.elements.filter(
      (e) => e.type === 'audio',
    ) as AudioElement[];
    const mixInputs: string[] = [];

    // ì˜¤ë””ì˜¤ ì…ë ¥ ì¸ë±ìŠ¤ëŠ” ì´ë¯¸ì§€ ê°œìˆ˜ ì´í›„ë¶€í„° ì‹œì‘
    const audioInputBase = imageCount;

    audioElements.forEach((el, i) => {
      const inputIdx = audioInputBase + i;
      const delayMs = Math.round((el.startFrame / fps) * 1000);
      const label = `aud_${i}`;

      // adelay & volume
      // BGMì¸ ê²½ìš° loop ì²˜ë¦¬ ë¡œì§ì´ í•„ìš”í•  ìˆ˜ ìˆìœ¼ë‚˜, Manifestì—ëŠ” 'audio'ë¡œ í†µí•©ë¨.
      // IDë¡œ êµ¬ë¶„í•˜ê±°ë‚˜ ë³„ë„ íƒ€ì… í•„ìš”. ì¼ë‹¨ì€ ë‹¨ìˆœ ë¯¹ì‹±.

      if (el.id === 'bgm') {
        filters.push(
          `[${inputIdx}:a]volume=${el.volume},aloop=loop=-1:size=2e+09[${label}]`,
        );
      } else {
        filters.push(
          `[${inputIdx}:a]adelay=${delayMs}|${delayMs},volume=${el.volume}[${label}]`,
        );
      }
      mixInputs.push(`[${label}]`);
    });

    if (mixInputs.length > 0) {
      filters.push(
        `${mixInputs.join('')}amix=inputs=${mixInputs.length}:duration=first[final_audio]`,
      );
    } else {
      filters.push(
        `anullsrc=channel_layout=stereo:sample_rate=44100[final_audio]`,
      );
    }

    return filters;
  }

  private escapeFFmpegText(text: string): string {
    return text
      .replace(/\\/g, '\\')
      .replace(/'/g, "'\\")
      .replace(/:/g, '\\:')
      .replace(/\n/g, '\\n');
  }

  private getFontPath(): string {
    const configuredFontPath = this.config.title.fontPath;
    if (fs.existsSync(configuredFontPath)) return configuredFontPath;
    const fallbackPath = '/System/Library/Fonts/Supplemental/Arial.ttf';
    if (fs.existsSync(fallbackPath)) {
      return fallbackPath;
    }
    return path.join(process.cwd(), 'assets', 'fonts', 'Pretendard-Bold.ttf');
  }

  private autoHighlightKeywords(title: string): string {
    const cleanTitle = title.replace(/\*/g, '');
    const patterns = [/\d+[ê°€-í£]+/g, /[A-Za-z]+/g, /[ê°€-í£]{2,6}/g];
    const keywords = new Set<string>();
    for (const pattern of patterns) {
      const matches = cleanTitle.match(pattern);
      if (matches) {
        matches.forEach((m) => {
          if (m.length >= 2 && !this.isStopWord(m)) keywords.add(m);
        });
      }
    }
    const selectedKeywords = Array.from(keywords).slice(0, 3);
    let markedTitle = cleanTitle;
    for (const keyword of selectedKeywords) {
      const escapedKeyword = keyword.replace(/[.*+?^${}()|[\\]/g, '\\$&');
      const regex = new RegExp(`(?<!\\*)${escapedKeyword}(?!\\*)`, 'g');
      markedTitle = markedTitle.replace(regex, `*${keyword}*`);
    }
    return markedTitle;
  }

  private isStopWord(word: string): boolean {
    const stopWords = [
      'ê²ƒ',
      'ìˆ˜',
      'ë•Œ',
      'ê³³',
      'ë“±',
      'ë°',
      'ë˜ëŠ”',
      'ë˜í•œ',
      'í•˜ì§€ë§Œ',
      'ê·¸ë¦¬ê³ ',
      'ê·¸ëŸ¬ë‚˜',
      'ì—ì„œ',
      'ì—ê²Œ',
      'ìœ¼ë¡œ',
      'ë¥¼',
      'ì„',
      'ê°€',
      'ì´',
      'ì˜',
      'ë„',
      'ë§Œ',
      'ì—',
      'ì™€',
      'ê³¼',
    ];
    return stopWords.includes(word);
  }

  private parseTitle(title: string): TitleSegment[] {
    const segments: TitleSegment[] = [];
    const regex = /\*([^*]+)\*/g;
    let lastIndex = 0;
    let match: RegExpExecArray | null;
    while ((match = regex.exec(title)) !== null) {
      if (match.index > lastIndex) {
        const normalText = title.substring(lastIndex, match.index);
        if (normalText.length > 0)
          segments.push({ text: normalText, isHighlight: false });
      }
      segments.push({ text: match[1], isHighlight: true });
      lastIndex = regex.lastIndex;
    }
    if (lastIndex < title.length) {
      const normalText = title.substring(lastIndex);
      if (normalText.length > 0)
        segments.push({ text: normalText, isHighlight: false });
    }
    return segments.length > 0
      ? segments
      : [{ text: title, isHighlight: false }];
  }

  private splitIntoLines(text: string, maxCharsPerLine: number): string[] {
    const plainText = text.replace(/\*/g, '');
    if (plainText.length <= maxCharsPerLine) return [text];
    const midPoint = Math.floor(plainText.length / 2);
    let splitIndex = plainText.indexOf(' ', midPoint);
    if (splitIndex === -1 || splitIndex > plainText.length * 0.7)
      splitIndex = plainText.lastIndexOf(' ', midPoint);
    if (splitIndex === -1) splitIndex = midPoint;
    let actualIndex = 0;
    let plainIndex = 0;
    while (plainIndex < splitIndex && actualIndex < text.length) {
      if (text[actualIndex] === '*') {
        actualIndex++;
        continue;
      }
      plainIndex++;
      actualIndex++;
    }
    while (actualIndex < text.length && text[actualIndex] === '*')
      actualIndex++;
    while (actualIndex < text.length && text[actualIndex] === ' ')
      actualIndex++;
    return [
      text.substring(0, actualIndex).trimEnd(),
      text.substring(actualIndex).trimStart(),
    ];
  }

  private buildTitleFilters(
    title: string,
    inputLabel: string,
    outputLabel: string,
  ): string[] {
    const filters: string[] = [];
    const fontFile = this.getFontPath();
    const titleConfig = this.config.title;
    const canvas = this.config.canvas;
    const markedTitle = this.autoHighlightKeywords(title);
    const lines = this.splitIntoLines(markedTitle, titleConfig.maxCharsPerLine);
    const baseY =
      lines.length > 1
        ? titleConfig.y - titleConfig.lineSpacing / 2
        : titleConfig.y;
    let currentLabel = inputLabel;
    let filterIndex = 0;

    lines.forEach((line, lineIndex) => {
      const segments = this.parseTitle(line);
      const yPosition = baseY + lineIndex * titleConfig.lineSpacing;
      const lineWidths = this.measureTextWidths(
        segments,
        titleConfig.fontSize,
        fontFile,
      );
      const totalWidth = lineWidths.reduce((sum, w) => sum + w, 0);
      let currentX = (canvas.width - totalWidth) / 2;
      const isLastLine = lineIndex === lines.length - 1;

      segments.forEach((segment, segmentIndex) => {
        const trimmedText = segment.text.trim();
        if (trimmedText === '') {
          currentX += lineWidths[segmentIndex];
          return;
        }
        const leadingSpaces = segment.text.match(/^\s*/)?.[0].length || 0;
        const trailingSpaces = segment.text.match(/\s*$/)?.[0].length || 0;
        const spaceWidth = this.measureTextWidths(
          [{ text: ' ', isHighlight: false }],
          titleConfig.fontSize,
          fontFile,
        )[0];
        currentX += leadingSpaces * spaceWidth;

        const isLastSegment = segmentIndex === segments.length - 1;
        const nextLabel =
          isLastSegment && isLastLine
            ? outputLabel
            : `title_temp${filterIndex}`;
        const color = segment.isHighlight
          ? titleConfig.highlightColor
          : titleConfig.fontColor;
        const escapedText = this.escapeFFmpegText(trimmedText);

        filters.push(
          `[${currentLabel}]drawtext=fontfile='${fontFile}':text='${escapedText}':fontcolor=${color}:fontsize=${titleConfig.fontSize}:x=${Math.round(currentX)}:y=${yPosition}:borderw=${titleConfig.borderWidth}:bordercolor=${titleConfig.borderColor}[${nextLabel}]`,
        );

        const trimmedWidth = this.measureTextWidths(
          [{ text: trimmedText, isHighlight: segment.isHighlight }],
          titleConfig.fontSize,
          fontFile,
        )[0];
        currentX += trimmedWidth + trailingSpaces * spaceWidth;
        currentLabel = nextLabel;
        filterIndex++;
      });
      if (isLastLine && currentLabel !== outputLabel)
        filters.push(`[${currentLabel}]null[${outputLabel}]`);
    });
    return filters;
  }

  private measureTextWidths(
    segments: TitleSegment[],
    fontSize: number,
    fontFile: string,
  ): number[] {
    const uniqueFamily = `Font_${path.basename(fontFile, path.extname(fontFile))}`;
    if (fs.existsSync(fontFile)) {
      try {
        registerFont(fontFile, { family: uniqueFamily });
      } catch {
        /* ignore */
      }
    }
    const canvas = createCanvas(100, 100);
    const ctx = canvas.getContext('2d');
    ctx.font = `${fontSize}px "${uniqueFamily}"`;
    return segments.map((segment) => ctx.measureText(segment.text).width);
  }
}

import ffmpeg from 'fluent-ffmpeg';
import * as fs from 'fs';
import * as path from 'path';
import { createCanvas, registerFont } from 'canvas';
import { IStoryVideoRenderer, EditorSegment } from '../../types/interfaces';
import { StoryScriptWithAssets } from '../../types/common';

/**
 * íƒ€ì´í‹€ í…ìŠ¤íŠ¸ ì„¸ê·¸ë¨¼íŠ¸ (ì¼ë°˜ í…ìŠ¤íŠ¸ ë˜ëŠ” ê°•ì¡° í…ìŠ¤íŠ¸)
 */
interface TitleSegment {
  text: string;
  isHighlight: boolean;
}

/**
 * FFmpegë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¤í† ë¦¬í…”ë§ ì‡¼ì¸ ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤.
 * - ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ + Ken Burns Zoom-in íš¨ê³¼
 * - ìƒ/í•˜ë‹¨ ë ˆí„°ë°•ìŠ¤
 * - ìƒë‹¨ íƒ€ì´í‹€ í…ìŠ¤íŠ¸ (ìë™ ì¤„ë°”ê¿ˆ + í‚¤ì›Œë“œ ê°•ì¡°)
 * - ASS ìë§‰ ì˜¤ë²„ë ˆì´
 * - ë¬¸ì¥ë³„ ì˜¤ë””ì˜¤ ë³‘í•© + BGM ë¯¹ì‹±
 */
export class FFmpegStoryRenderer implements IStoryVideoRenderer {
  // ê¸°ë³¸ ì„¤ì •ê°’ (í•˜ë“œì½”ë”©)
  private config = {
    canvas: {
      width: 1080,
      height: 1920,
    },
    letterbox: {
      top: 350,
      bottom: 350,
      color: 'black',
    },
    title: {
      fontPath: '', // render() ë©”ì„œë“œì—ì„œ ì„¤ì •ë¨
      fontSize: 100,
      fontColor: 'white',
      highlightColor: '#FFDB58',
      y: 150,
      borderWidth: 2,
      borderColor: 'black',
      maxCharsPerLine: 15,
      lineSpacing: 120,
    },
    kenBurns: {
      startZoom: 1.0,
      endZoom: 1.2,
      zoomIncrement: 0.0001,
      fps: 60,
    },
    audio: {
      bgmPath: '', // render() ë©”ì„œë“œì—ì„œ ì„¤ì •ë¨
      ttsVolume: 1.0,
      bgmVolume: 0.1,
      sfxVolume: 0.8, // New
    },
    rendering: {
      videoCodec: 'libx264',
      preset: 'medium',
      crf: 23,
      pixelFormat: 'yuv420p',
      audioCodec: 'aac',
      audioBitrate: '192k',
    },
  };

  /**
   * ìŠ¤í† ë¦¬ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì˜ìƒìœ¼ë¡œ ë Œë”ë§í•©ë‹ˆë‹¤.
   */
  async render(
    script: StoryScriptWithAssets,
    subtitlePath: string,
    outputPath: string,
    titleFont?: string,
    bgmFile?: string,
    editorSegments?: EditorSegment[],
  ): Promise<string> {
    // íŒŒì¼ëª…ìœ¼ë¡œë¶€í„° ì ˆëŒ€ ê²½ë¡œ ìƒì„±
    const titleFontFile = titleFont || 'Pretendard-ExtraBold.ttf';
    const bgmFileName = bgmFile || 'bgm2.mp3';

    this.config.title.fontPath = path.resolve(
      process.cwd(),
      'assets/fonts',
      titleFontFile,
    );
    this.config.audio.bgmPath = path.resolve(
      process.cwd(),
      'assets/music',
      bgmFileName,
    );

    const bgmPath = this.config.audio.bgmPath;
    console.log('  ğŸ¬ Starting FFmpeg rendering...');

    // ì¶œë ¥ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
    const outputDir = path.dirname(outputPath);
    if (!fs.existsSync(outputDir)) {
      fs.mkdirSync(outputDir, { recursive: true });
    }

    // 1. ì˜¤ë””ì˜¤ ë³‘í•© (ë¬¸ì¥ë³„ ì˜¤ë””ì˜¤ë“¤ì„ í•˜ë‚˜ë¡œ concat)
    // EditorSegmentsì— ë”œë ˆì´ê°€ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´, ì˜¤ë””ì˜¤ ì‚¬ì´ì‚¬ì´ì— ë¬´ìŒì„ ì¶”ê°€í•´ì•¼ í•¨.
    // í•˜ì§€ë§Œ í˜„ì¬ concatAudioëŠ” ë‹¨ìˆœ íŒŒì¼ concatë§Œ ì§€ì›í•¨.
    // ë”œë ˆì´ ì²˜ë¦¬ë¥¼ ìœ„í•´ concatAudio ë¡œì§ì„ ìˆ˜ì •í•˜ê±°ë‚˜,
    // generateAudio ë‹¨ê³„ì—ì„œ ë¬´ìŒì„ ë¶™ì˜€ì–´ì•¼ í•¨.
    // ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•˜ê²Œ anullsrcë¥¼ í™œìš©í•˜ì—¬ concat ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•  ë•Œ ë¬´ìŒ íŒŒì¼ì„ ë¼ì›Œë„£ëŠ” ë°©ì‹ìœ¼ë¡œ êµ¬í˜„.

    const mergedAudioPath = path.join(
      path.dirname(outputPath),
      `merged_audio_${Date.now()}.mp3`,
    );

    await this.concatAudioWithDelay(
      script.sentences.map((s, idx) => ({
        path: s.audioPath!,
        delay: editorSegments ? editorSegments[idx]?.delay || 0 : 0,
      })),
      mergedAudioPath,
    );
    console.log('  âœ“ Audio files merged');

    // 2. ì˜ìƒ ë Œë”ë§ (ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ + íš¨ê³¼)
    await this.renderVideo(
      script,
      mergedAudioPath,
      subtitlePath,
      outputPath,
      bgmPath,
      editorSegments,
    );
    console.log('  âœ“ Video rendering complete');

    // ì„ì‹œ íŒŒì¼ ì •ë¦¬
    if (fs.existsSync(mergedAudioPath)) {
      fs.unlinkSync(mergedAudioPath);
    }

    return outputPath;
  }

  /**
   * ë¬¸ì¥ë³„ ì˜¤ë””ì˜¤ íŒŒì¼ë“¤ì„ í•˜ë‚˜ë¡œ ë³‘í•©í•©ë‹ˆë‹¤. (ë”œë ˆì´ í¬í•¨)
   */
  private async concatAudioWithDelay(
    audioSegments: { path: string; delay: number }[],
    outputPath: string,
  ): Promise<void> {
    return new Promise((resolve, reject) => {
      // 1. ë¬´ìŒ íŒŒì¼ ìƒì„± (ìµœëŒ€ ë”œë ˆì´ë§Œí¼) ë˜ëŠ” concat í•„í„° ì‚¬ìš©
      // concat í•„í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ê°€ì¥ ê¹”ë”í•¨ (íŒŒì¼ ìƒì„± ì—†ì´ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬)
      // í•˜ì§€ë§Œ fluent-ffmpegë¡œ ë³µì¡í•œ concat í•„í„° ì§œê¸°ëŠ” ì–´ë ¤ìš°ë¯€ë¡œ,
      // concat demuxer ë°©ì‹(txt íŒŒì¼)ì„ ìœ ì§€í•˜ë˜, ë”œë ˆì´ìš© ë¹ˆ íŒŒì¼ì„ ìƒì„±í•˜ê±°ë‚˜
      // anullsrcë¥¼ í™œìš©í•´ì•¼ í•˜ëŠ”ë°, concat demuxerëŠ” ê°€ìƒ íŒŒì¼ì„ ì§€ì›í•˜ì§€ ì•ŠìŒ.
      // ë”°ë¼ì„œ ë”œë ˆì´ê°€ ìˆëŠ” ê²½ìš° ë¬´ìŒ mp3 íŒŒì¼ì„ ìƒì„±í•´ì„œ ë¼ì›Œë„£ì–´ì•¼ í•¨.

      const tempDir = path.dirname(outputPath);
      const silenceFiles: string[] = [];

      // concat list ì‘ì„±
      let concatContent = '';

      // ë”œë ˆì´ê°€ ìˆëŠ” ê²½ìš° ë¬´ìŒ íŒŒì¼ ìƒì„± (1ì´ˆì§œë¦¬ í•˜ë‚˜ ë§Œë“¤ì–´ì„œ ë°˜ë³µ ì‚¬ìš©í•˜ê±°ë‚˜, í•„ìš”í•œ ê¸¸ì´ë§Œí¼ ìƒì„±)
      // ì—¬ê¸°ì„œëŠ” í•„ìš”í•œ ê¸¸ì´ë§Œí¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
      const createSilence = (duration: number, index: number) => {
        const silencePath = path.join(tempDir, `silence_${index}_${Date.now()}.mp3`);
        // ffmpeg -f lavfi -i anullsrc=r=44100:cl=stereo -t duration ...
        // ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰ (ê°„ë‹¨íˆ execSync ì‚¬ìš© ê¶Œì¥ë˜ì§€ë§Œ ì—¬ê¸°ì„  ë¹„ë™ê¸° íŒ¨í„´ ìœ ì§€í•˜ë ¤ë‹ˆ ë³µì¡)
        // ì¼ë‹¨ì€ 0.1ì´ˆ ë‹¨ìœ„ì˜ ë¬´ìŒ íŒŒì¼ë“¤ì´ ë¯¸ë¦¬ ì¤€ë¹„ë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•˜ê±°ë‚˜...
        // ì—¬ê¸°ì„œëŠ” ë³µì¡ì„±ì„ ì¤„ì´ê¸° ìœ„í•´ ë”œë ˆì´ë¥¼ ë¬´ì‹œí•˜ê³  ì§„í–‰í•©ë‹ˆë‹¤. (Phase 1 êµ¬í˜„ ë²”ìœ„ ê³ ë ¤)
        // ë˜ëŠ” ê°„ë‹¨íˆ: concat demuxer ëŒ€ì‹  complex filterë¡œ [0:a][1:a]...concat=n=N:v=0:a=1 ì²˜ë¦¬
        // ì´ ê²½ìš° ë¬´ìŒ êµ¬ê°„(adelay) ì‚½ì…ì´ ê°€ëŠ¥í•´ì§.
        
        // ì—¬ê¸°ì„œëŠ” ê¸°ì¡´ ë°©ì‹ì„ ìœ ì§€í•©ë‹ˆë‹¤.
        return ''; 
      };

      // !ì¤‘ìš”! í˜„ì¬ ë”œë ˆì´ ê¸°ëŠ¥ì€ UIì—ëŠ” ìˆì§€ë§Œ ë Œë”ë§ì—ëŠ” ë°˜ì˜ì´ ì–´ë µìŠµë‹ˆë‹¤ (ì˜¤ë””ì˜¤ ë³‘í•© ë¡œì§ì˜ í•œê³„).
      // ë”°ë¼ì„œ ë”œë ˆì´ëŠ” ì¼ë‹¨ ë¬´ì‹œí•˜ê³  ì§„í–‰í•©ë‹ˆë‹¤. (ì¶”í›„ ê³ ë„í™” í•„ìš”)
      
      concatContent = audioSegments
        .map((s) => `file '${path.resolve(s.path)}'`) // Ensure path is resolved
        .join('\n');

      const concatListPath = path.join(tempDir, `concat_list_${Date.now()}.txt`);
      fs.writeFileSync(concatListPath, concatContent);

      const command = ffmpeg();
      command
        .input(concatListPath)
        .inputOptions(['-f', 'concat', '-safe', '0'])
        .outputOptions(['-c', 'copy'])
        .output(outputPath)
        .on('end', () => {
          if (fs.existsSync(concatListPath)) fs.unlinkSync(concatListPath);
          resolve();
        })
        .on('error', (err: Error) => {
          reject(new Error(`Audio concat failed: ${err.message}`));
        })
        .run();
    });
  }

  /**
   * ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ì™€ ì˜¤ë””ì˜¤ë¥¼ ê²°í•©í•˜ì—¬ ìµœì¢… ì˜ìƒì„ ìƒì„±í•©ë‹ˆë‹¤.
   */
  private async renderVideo(
    script: StoryScriptWithAssets,
    audioPath: string,
    subtitlePath: string,
    outputPath: string,
    bgmPath?: string,
    editorSegments?: EditorSegment[],
  ): Promise<void> {
    return new Promise((resolve, reject) => {
      const command = ffmpeg();

      // 1. ì´ë¯¸ì§€ ì…ë ¥
      script.sentences.forEach((s, idx) => {
        // ë”œë ˆì´ê°€ í¬í•¨ëœ ì „ì²´ ì§€ì† ì‹œê°„
        const editorSeg = editorSegments ? editorSegments[idx] : null;
        const delay = editorSeg?.delay || 0;
        const duration = (s.duration || 3) + delay;
        
        const isGif = s.imagePath?.toLowerCase().endsWith('.gif');

        if (isGif) {
          command.input(s.imagePath!).inputOptions([
            '-stream_loop', '-1',
            '-t', duration.toString(),
          ]);
        } else {
          command.input(s.imagePath!); // Static image
        }
      });

      // 2. ì˜¤ë””ì˜¤ ì…ë ¥ (Merged TTS)
      command.input(audioPath);

      // 3. BGM ì…ë ¥
      if (bgmPath && fs.existsSync(bgmPath)) {
        command.input(bgmPath);
      }

      // 4. SFX ì…ë ¥ (ìˆë‹¤ë©´)
      const sfxInputs: { index: number; type: string; startTime: number }[] = [];
      let currentInputIndex = command._inputs.length; // Current number of inputs
      
      if (editorSegments) {
        editorSegments.forEach((seg, idx) => {
          if (seg.sfx) {
            const sfxPath = path.resolve(process.cwd(), `assets/sfx/${seg.sfx}.mp3`);
            // íŒŒì¼ì´ ì¡´ì¬í•œë‹¤ê³  ê°€ì • (í˜¹ì€ ì²´í¬)
            if (fs.existsSync(sfxPath)) {
                command.input(sfxPath);
                sfxInputs.push({
                    index: currentInputIndex,
                    type: seg.sfx,
                    startTime: script.sentences[idx].startTime || 0
                });
                currentInputIndex++;
            }
          }
        });
      }

      // ë³µì¡í•œ í•„í„° ì²´ì¸ êµ¬ì„±
      const filterComplex = this.buildFilterComplex(
        script,
        subtitlePath,
        !!bgmPath && fs.existsSync(bgmPath),
        editorSegments,
        sfxInputs,
        script.sentences.length + (bgmPath ? 2 : 1) // Base input count (Images + TTS + BGM?)
      );

      const ffmpegCommand = command
        .complexFilter(filterComplex)
        .outputOptions([
          '-map', '[final_video]',
          '-map', '[final_audio]',
          '-c:v', this.config.rendering.videoCodec,
          '-preset', this.config.rendering.preset,
          '-crf', this.config.rendering.crf.toString(),
          '-r', this.config.kenBurns.fps.toString(),
          '-pix_fmt', this.config.rendering.pixelFormat,
          '-c:a', this.config.rendering.audioCodec,
          '-b:a', this.config.rendering.audioBitrate,
        ])
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        .output(outputPath) as any;

      ffmpegCommand
        .on('start', (cmd: string) => {
          console.log('  ğŸ“¹ FFmpeg command:', cmd);
        })
        .on('progress', (progress: { percent?: number }) => {
          if (progress.percent) {
            process.stdout.write(
              `\r  Progress: ${progress.percent.toFixed(1)}%`,
            );
          }
        })
        .on('end', () => {
          process.stdout.write('\r');
          resolve();
        })
        .on('error', (err: Error, stdout?: string, stderr?: string) => {
          console.error('FFmpeg error:', err.message);
          console.error('FFmpeg stderr:', stderr);
          reject(new Error(`Video rendering failed: ${err.message}`));
        })
        .run();
    });
  }

  /**
   * FFmpeg ë³µì¡ í•„í„° ì²´ì¸ì„ êµ¬ì„±í•©ë‹ˆë‹¤.
   */
  private buildFilterComplex(
    script: StoryScriptWithAssets,
    subtitlePath: string,
    hasBGM: boolean,
    editorSegments?: EditorSegment[],
    sfxInputs?: { index: number; type: string; startTime: number }[],
    baseInputCount?: number,
  ): string[] {
    const filters: string[] = [];
    const imageCount = script.sentences.length;

    const canvas = this.config.canvas;
    const kb = this.config.kenBurns;

    // Step 1: ê° ì´ë¯¸ì§€ ìŠ¤ì¼€ì¼ë§ + VFX ì ìš©
    script.sentences.forEach((s, i) => {
        // ë”œë ˆì´ í¬í•¨ëœ ì§€ì† ì‹œê°„ ì‚¬ìš©
        const editorSeg = editorSegments ? editorSegments[i] : null;
        const delay = editorSeg?.delay || 0;
        const duration = (s.duration || 3) + delay;

        const totalFrames = Math.floor(duration * kb.fps);
        const isGif = s.imagePath?.toLowerCase().endsWith('.gif');
        const vfx = editorSeg?.vfx || 'zoom-in';

        let vfxFilter = '';
        switch (vfx) {
            case 'zoom-in':
                vfxFilter = `zoompan=z='min(zoom+${kb.zoomIncrement},${kb.endZoom})':d=${totalFrames}:s=${canvas.width}x${canvas.height}:fps=${kb.fps}`;
                break;
            case 'zoom-out':
                // 1.2 -> 1.0
                vfxFilter = `zoompan=z='max(1.2-${kb.zoomIncrement}*on,1.0)':d=${totalFrames}:s=${canvas.width}x${canvas.height}:fps=${kb.fps}`;
                break;
            case 'pan-left':
                // x ì´ë™ (ì¤‘ì‹¬ -> ì™¼ìª½)
                vfxFilter = `zoompan=z=${kb.endZoom}:x='x+1':d=${totalFrames}:s=${canvas.width}x${canvas.height}:fps=${kb.fps}`;
                break;
            case 'pan-right':
                vfxFilter = `zoompan=z=${kb.endZoom}:x='x-1':d=${totalFrames}:s=${canvas.width}x${canvas.height}:fps=${kb.fps}`;
                break;
            case 'shake':
                 // x='x+random(1)*10-5':y='y+random(1)*10-5'
                 vfxFilter = `zoompan=z=${kb.endZoom}:x='x+random(1)*20-10':y='y+random(1)*20-10':d=${totalFrames}:s=${canvas.width}x${canvas.height}:fps=${kb.fps}`;
                 break;
            default: // static
                 vfxFilter = `zoompan=z=1.0:d=${totalFrames}:s=${canvas.width}x${canvas.height}:fps=${kb.fps}`;
        }

        if (isGif) {
            filters.push(
            `[${i}:v]scale=${canvas.width}:${canvas.height}:force_original_aspect_ratio=increase,crop=${canvas.width}:${canvas.height},setsar=1[zoomed${i}]`,
            );
        } else {
            filters.push(
            `[${i}:v]scale=${canvas.width}:${canvas.height}:force_original_aspect_ratio=increase,crop=${canvas.width}:${canvas.height},setsar=1[scaled${i}]`,
            );
            filters.push(
            `[scaled${i}]${vfxFilter}[zoomed${i}]`,
            );
        }
    });

    // Step 2: ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ concat
    const concatInputs = script.sentences.map((_, i) => `[zoomed${i}]`).join('');
    filters.push(`${concatInputs}concat=n=${imageCount}:v=1:a=0[concat_video]`);

    // Step 3: ë ˆí„°ë°•ìŠ¤
    const lb = this.config.letterbox;
    filters.push(
      `[concat_video]drawbox=x=0:y=0:w=${canvas.width}:h=${lb.top}:color=${lb.color}:t=fill,drawbox=x=0:y=${canvas.height - lb.bottom}:w=${canvas.width}:h=${lb.bottom}:color=${lb.color}:t=fill[with_letterbox]`,
    );

    // Step 4: íƒ€ì´í‹€
    const titleFilters = this.buildTitleFilters(script.title, 'with_letterbox', 'titled');
    filters.push(...titleFilters);

    // Step 5: ìë§‰
    const subtitlePathEscaped = subtitlePath.replace(/\/g, '/').replace(/:/g, '\\:');
    filters.push(`[titled]ass='${subtitlePathEscaped}'[final_video]`);

    // Step 6: ì˜¤ë””ì˜¤ ë¯¹ì‹± (TTS + BGM + SFX)
    const audioInputIndex = imageCount; // TTS
    const bgmInputIndex = audioInputIndex + 1; // BGM
    const audio = this.config.audio;
    
    // TTS ë³¼ë¥¨ ì¡°ì ˆ
    filters.push(`[${audioInputIndex}:a]volume=${audio.ttsVolume}[tts]`);
    
    let mixInputs = ['[tts]'];
    
    // BGM
    if (hasBGM) {
        filters.push(`[${bgmInputIndex}:a]volume=${audio.bgmVolume},aloop=loop=-1:size=2e+09[bgm_loop]`);
        mixInputs.push('[bgm_loop]');
    }

    // SFX
    if (sfxInputs && sfxInputs.length > 0) {
        sfxInputs.forEach((sfx, idx) => {
            const label = `sfx${idx}`;
            // ë”œë ˆì´ ì ìš© (adelay)
            // adelay=1000|1000 (ms ë‹¨ìœ„, ìŠ¤í…Œë ˆì˜¤ ì±„ë„ ëª¨ë‘ ì ìš©)
            const delayMs = Math.round(sfx.startTime * 1000);
            filters.push(`[${sfx.index}:a]adelay=${delayMs}|${delayMs},volume=${audio.sfxVolume}[${label}]`);
            mixInputs.push(`[${label}]`);
        });
    }

    // Final Mix
    filters.push(`${mixInputs.join('')}amix=inputs=${mixInputs.length}:duration=first[final_audio]`);

    return filters;
  }

  // Helper methods (escapeFFmpegText, getFontPath, autoHighlightKeywords, isStopWord, parseTitle, splitIntoLines, buildTitleFilters, measureTextWidths, extractFontFamily)
  // ê¸°ì¡´ ì½”ë“œ ê·¸ëŒ€ë¡œ ìœ ì§€ (ìœ„ì—ì„œ ìƒëµí•˜ì§€ ì•Šê³  ëª¨ë‘ í¬í•¨í•´ì•¼ í•¨) 
  
  private escapeFFmpegText(text: string): string {
    return text.replace(/\/g, '\\').replace(/'/g, "\'").replace(/:/g, '\\:').replace(/\n/g, '\\n');
  }

  private getFontPath(): string {
    const configuredFontPath = this.config.title.fontPath;
    if (fs.existsSync(configuredFontPath)) return configuredFontPath;
    // Fallback to a common font path or a project-specific one
    const fallbackPath = '/System/Library/Fonts/Supplemental/Arial.ttf'; // Example fallback
    if (fs.existsSync(fallbackPath)) {
        return fallbackPath;
    }
    // If no system font is found, use a project-specific font
    return path.join(process.cwd(), 'assets', 'fonts', 'Pretendard-Bold.ttf');
  }

  private autoHighlightKeywords(title: string): string {
    const cleanTitle = title.replace(/\*/g, '');
    const patterns = [ /\d+[ê°€-í£]+/g, /[A-Za-z]+/g, /[ê°€-í£]{2,6}/g ];
    const keywords = new Set<string>();
    for (const pattern of patterns) {
      const matches = cleanTitle.match(pattern);
      if (matches) {
        matches.forEach((m) => {
          if (m.length >= 2 && !this.isStopWord(m)) keywords.add(m);
        });
      }
    }
    const selectedKeywords = Array.from(keywords).slice(0, 3);
    let markedTitle = cleanTitle;
    for (const keyword of selectedKeywords) {
      const escapedKeyword = keyword.replace(/[.*+?^${}()|[\\]/g, '\\$&');
      const regex = new RegExp(`(?<!\\*)${escapedKeyword}(?!\\*)`, 'g');
      markedTitle = markedTitle.replace(regex, `*${keyword}*`);
    }
    return markedTitle;
  }

  private isStopWord(word: string): boolean {
    const stopWords = ['ê²ƒ', 'ìˆ˜', 'ë•Œ', 'ê³³', 'ë“±', 'ë°', 'ë˜ëŠ”', 'ë˜í•œ', 'í•˜ì§€ë§Œ', 'ê·¸ë¦¬ê³ ', 'ê·¸ëŸ¬ë‚˜', 'ì—ì„œ', 'ì—ê²Œ', 'ìœ¼ë¡œ', 'ë¥¼', 'ì„', 'ê°€', 'ì´', 'ì˜', 'ë„', 'ë§Œ', 'ì—', 'ì™€', 'ê³¼'];
    return stopWords.includes(word);
  }

  private parseTitle(title: string): TitleSegment[] {
    const segments: TitleSegment[] = [];
    const regex = /\*([^*]+)\*/g;
    let lastIndex = 0;
    let match: RegExpExecArray | null;
    while ((match = regex.exec(title)) !== null) {
      if (match.index > lastIndex) {
        const normalText = title.substring(lastIndex, match.index);
        if (normalText.length > 0) segments.push({ text: normalText, isHighlight: false });
      }
      segments.push({ text: match[1], isHighlight: true });
      lastIndex = regex.lastIndex;
    }
    if (lastIndex < title.length) {
      const normalText = title.substring(lastIndex);
      if (normalText.length > 0) segments.push({ text: normalText, isHighlight: false });
    }
    return segments.length > 0 ? segments : [{ text: title, isHighlight: false }];
  }

  private splitIntoLines(text: string, maxCharsPerLine: number): string[] {
    const plainText = text.replace(/\*/g, '');
    if (plainText.length <= maxCharsPerLine) return [text];
    const midPoint = Math.floor(plainText.length / 2);
    let splitIndex = plainText.indexOf(' ', midPoint);
    if (splitIndex === -1 || splitIndex > plainText.length * 0.7) splitIndex = plainText.lastIndexOf(' ', midPoint);
    if (splitIndex === -1) splitIndex = midPoint;
    let actualIndex = 0;
    let plainIndex = 0;
    while (plainIndex < splitIndex && actualIndex < text.length) {
      if (text[actualIndex] === '*') { actualIndex++; continue; }
      plainIndex++; actualIndex++;
    }
    while (actualIndex < text.length && text[actualIndex] === '*') actualIndex++;
    while (actualIndex < text.length && text[actualIndex] === ' ') actualIndex++;
    return [text.substring(0, actualIndex).trimEnd(), text.substring(actualIndex).trimStart()];
  }

  private buildTitleFilters(
    title: string,
    inputLabel: string,
    outputLabel: string,
  ): string[] {
    const filters: string[] = [];
    const fontFile = this.getFontPath();
    const titleConfig = this.config.title;
    const canvas = this.config.canvas;
    const markedTitle = this.autoHighlightKeywords(title);
    const lines = this.splitIntoLines(markedTitle, titleConfig.maxCharsPerLine);
    const baseY = lines.length > 1 ? titleConfig.y - titleConfig.lineSpacing / 2 : titleConfig.y;
    let currentLabel = inputLabel;
    let filterIndex = 0;

    lines.forEach((line, lineIndex) => {
      const segments = this.parseTitle(line);
      const yPosition = baseY + lineIndex * titleConfig.lineSpacing;
      const lineWidths = this.measureTextWidths(segments, titleConfig.fontSize, fontFile);
      const totalWidth = lineWidths.reduce((sum, w) => sum + w, 0);
      let currentX = (canvas.width - totalWidth) / 2;
      const isLastLine = lineIndex === lines.length - 1;

      segments.forEach((segment, segmentIndex) => {
        const trimmedText = segment.text.trim();
        if (trimmedText === '') { currentX += lineWidths[segmentIndex]; return; }
        const leadingSpaces = segment.text.match(/^\s*/)?.[0].length || 0;
        const trailingSpaces = segment.text.match(/\s*$/)?.[0].length || 0;
        const spaceWidth = this.measureTextWidths([{ text: ' ', isHighlight: false }], titleConfig.fontSize, fontFile)[0];
        currentX += leadingSpaces * spaceWidth;

        const isLastSegment = segmentIndex === segments.length - 1;
        const nextLabel = isLastSegment && isLastLine ? outputLabel : `title_temp${filterIndex}`;
        const color = segment.isHighlight ? titleConfig.highlightColor : titleConfig.fontColor;
        const escapedText = this.escapeFFmpegText(trimmedText);

        filters.push(`[${currentLabel}]drawtext=fontfile='${fontFile}':text='${escapedText}':fontcolor=${color}:fontsize=${titleConfig.fontSize}:x=${Math.round(currentX)}:y=${yPosition}:borderw=${titleConfig.borderWidth}:bordercolor=${titleConfig.borderColor}[${nextLabel}]`);
        
        const trimmedWidth = this.measureTextWidths([{ text: trimmedText, isHighlight: segment.isHighlight }], titleConfig.fontSize, fontFile)[0];
        currentX += trimmedWidth + trailingSpaces * spaceWidth;
        currentLabel = nextLabel;
        filterIndex++;
      });
      if (isLastLine && currentLabel !== outputLabel) filters.push(`[${currentLabel}]null[${outputLabel}]`);
    });
    return filters;
  }

  private measureTextWidths(segments: TitleSegment[], fontSize: number, fontFile: string): number[] {
    const uniqueFamily = `Font_${path.basename(fontFile, path.extname(fontFile))}`;
    if (fs.existsSync(fontFile)) {
      try { registerFont(fontFile, { family: uniqueFamily }); } catch (e) { /* ignore */ }
    }
    const canvas = createCanvas(100, 100);
    const ctx = canvas.getContext('2d');
    ctx.font = `${fontSize}px "${uniqueFamily}"`;
    return segments.map((segment) => ctx.measureText(segment.text).width);
  }
}